{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIDy3Fr6a8wL",
        "outputId": "621b9321-099f-43aa-de52-c0a1db5300fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0.0: 0.493199999999962, 1.0: 0.5057999999999606, 2.0: 0.0010000000000000002}\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow import keras\n",
        "import csv\n",
        "import numpy as np\n",
        "from collections import deque\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import math\n",
        "from tensorflow.keras.layers import Input\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "\n",
        "# The size of the dataset to work with\n",
        "size = 10000\n",
        "\n",
        "\n",
        "# The number of time steps in each example\n",
        "timesteps = 30\n",
        "\n",
        "# The size of each batch\n",
        "batch_size = 16\n",
        "\n",
        "# Number of Epochs\n",
        "epochs = 100\n",
        "\n",
        "\n",
        "def tuple_generator(x_data, y_data, timesteps):\n",
        "    ''' Input: A numpy array of Time-series Data\n",
        "        Yields: A batch of Training and testing data '''\n",
        "\n",
        "    i = 0\n",
        "    y_data = y_data[timesteps-1:]\n",
        "    while True:\n",
        "        x_batch = np.stack([x_data[j:j+timesteps] for j in range(i, min(batch_size + i, len(x_data) + 1 - timesteps))])\n",
        "        y_batch = y_data[i:i+batch_size]\n",
        "        i += batch_size\n",
        "        if i >= len(x_data) + 1 - timesteps:\n",
        "            i = 0\n",
        "        yield x_batch, y_batch\n",
        "\n",
        "def get_column_names(name):\n",
        "    \"\"\"Returns the column names of a csv file.\"\"\"\n",
        "    with open(name) as f:\n",
        "        reader = csv.reader(f)\n",
        "        return next(reader)\n",
        "\n",
        "def get_last_lines(name, n=5000):\n",
        "    \"\"\"Returns the last n lines of a file as a numpy array.\"\"\"\n",
        "    with open(name) as f:\n",
        "        lines = deque(csv.reader(f), maxlen=n+1)\n",
        "    return np.array(lines)[:-1]\n",
        "\n",
        "def build_generators(name, timesteps):\n",
        "    \"\"\"Builds the generators for the neural network.\"\"\"\n",
        "    columns = get_column_names(name)\n",
        "    data = get_last_lines(name, size)\n",
        "    frame = pd.DataFrame(data, columns=columns)\n",
        "    frame.pop('Timestamp')\n",
        "    frame = frame.astype(float)\n",
        "    features_to_scale = [\"SMA_10\", \"SMA_50\", \"RSI_14\", \"Middle_Band\", \"Upper_Band\", \"Lower_Band\", \"TOD\"]\n",
        "    scaler = StandardScaler()\n",
        "    frame[features_to_scale] = scaler.fit_transform(frame[features_to_scale])\n",
        "    target = frame.pop('Return_Signal')\n",
        "    weights = {}\n",
        "    for i in target:\n",
        "        weights[i] = weights.get(i, 0) + 1/len(target)\n",
        "    print(weights)\n",
        "    xtr, xte, ytr, yte = train_test_split(frame, target, test_size=0.2, shuffle=False)\n",
        "    train_shape = xtr.shape\n",
        "    train_gen = tuple_generator(xtr.to_numpy(), ytr.to_numpy(), timesteps)\n",
        "    test_gen = tuple_generator(xte.to_numpy(), yte.to_numpy(), timesteps)\n",
        "    test_shape = xte.shape\n",
        "    return  train_gen, test_gen, train_shape, test_shape, weights\n",
        "\n",
        "\n",
        "train_gen, test_gen, train_shape, test_shape, weights = build_generators(\"drive/MyDrive/Kraken Coins/XBTUSD_5_with_features.csv\", timesteps)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOsszKHnhrYg"
      },
      "outputs": [],
      "source": [
        "class ClassSpecificAccuracy(tf.keras.metrics.Metric):\n",
        "    def __init__(self, target_class=2, name=\"class_accuracy\", **kwargs):\n",
        "        name = f\"{name}_{target_class}\"\n",
        "        super().__init__(name=name, **kwargs)\n",
        "        self.target_class = target_class\n",
        "        self.correct = self.add_weight(name=\"correct\", initializer=\"zeros\")\n",
        "        self.total = self.add_weight(name=\"total\", initializer=\"zeros\")\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        y_true = tf.cast(y_true, tf.int64)\n",
        "        y_pred_labels = tf.argmax(y_pred, axis=1, output_type=tf.int64)\n",
        "\n",
        "        mask = tf.equal(y_true, self.target_class)\n",
        "        correct_preds = tf.reduce_sum(tf.cast(tf.logical_and(mask, tf.equal(y_pred_labels, y_true)), tf.float32))\n",
        "        total_preds = tf.reduce_sum(tf.cast(mask, tf.float32))\n",
        "\n",
        "        self.correct.assign_add(correct_preds)\n",
        "        self.total.assign_add(total_preds)\n",
        "\n",
        "    def result(self):\n",
        "        return self.correct / (self.total + tf.keras.backend.epsilon())\n",
        "\n",
        "    def reset_states(self):\n",
        "        self.correct.assign(0)\n",
        "        self.total.assign(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYFX-ul8EhGw",
        "outputId": "69471070-c5ac-4e6c-b73d-87dbb0626cc6"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'Input' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-a4843234c5a4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Specify list of layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m layer_list = [\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimesteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mBidirectional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mBidirectional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Input' is not defined"
          ]
        }
      ],
      "source": [
        "#Specify list of layers\n",
        "layer_list = [\n",
        "    Input(shape=(timesteps, train_shape[1])),\n",
        "    Bidirectional(layers.LSTM(128, return_sequences=True)),\n",
        "    Bidirectional(layers.LSTM(128, return_sequences=True)),\n",
        "    Bidirectional(layers.LSTM(128, return_sequences=False)),\n",
        "    layers.Dense(100, activation='relu'),\n",
        "    layers.Dense(3, activation='softmax')\n",
        "\n",
        "]\n",
        "\n",
        "model = models.Sequential(layer_list)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy', ClassSpecificAccuracy(target_class=2), ClassSpecificAccuracy(target_class=1), ClassSpecificAccuracy(target_class=0)])\n",
        "\n",
        "model.fit(train_gen, epochs=epochs, steps_per_epoch=math.ceil(train_shape[0] / batch_size), validation_data=test_gen, validation_steps= math.ceil(test_shape[0] / batch_size))\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_gen, steps=math.ceil(test_shape[0] / batch_size))\n",
        "print('Test accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZH7Moy8unrT9"
      },
      "outputs": [],
      "source": [
        "from google.colab import runtime\n",
        "import time\n",
        "\n",
        "time.sleep(15)\n",
        "runtime.unassign()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
