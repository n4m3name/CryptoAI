{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uiFkE7yd836h",
        "outputId": "b36cdef7-e2dc-4692-e582-ff7b9ee1689a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 0.6542931028838914, 1: 0.8589231232005501, 2: 3.2532552083333335}\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow import keras\n",
        "import csv\n",
        "import numpy as np\n",
        "from collections import deque\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import math\n",
        "from tensorflow.keras.layers import Input\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "# The size of the dataset to work with\n",
        "size = 50000\n",
        "\n",
        "\n",
        "# The number of time steps in each example\n",
        "timesteps = 25\n",
        "\n",
        "# The size of each batch\n",
        "batch_size = 16\n",
        "\n",
        "# Number of Epochs\n",
        "epochs = 100\n",
        "\n",
        "\n",
        "def sequence_maker(x_data, y_data, timesteps):\n",
        "    ''' Input: A numpy array of Time-series Data\n",
        "        Yields: A batch of Training and testing data '''\n",
        "\n",
        "    sequences = np.array([x_data[i:i+timesteps] for i in range(len(x_data) + 1 - timesteps)])\n",
        "    labels = np.array(y_data[timesteps-1:])\n",
        "    return sequences, labels\n",
        "\n",
        "def get_column_names(name):\n",
        "    \"\"\"Returns the column names of a csv file.\"\"\"\n",
        "    with open(name) as f:\n",
        "        reader = csv.reader(f)\n",
        "        return next(reader)\n",
        "\n",
        "def get_last_lines(name, n=5000):\n",
        "    \"\"\"Returns the last n lines of a file as a numpy array.\"\"\"\n",
        "    with open(name) as f:\n",
        "        lines = deque(csv.reader(f), maxlen=n+1)\n",
        "    return np.array(lines)[:-1]\n",
        "\n",
        "def build_generators(name, timesteps):\n",
        "    \"\"\"Builds the generators for the neural network.\"\"\"\n",
        "    columns = get_column_names(name)\n",
        "    data = get_last_lines(name, size)\n",
        "    frame = pd.DataFrame(data, columns=columns)\n",
        "    frame.pop('Timestamp')\n",
        "    frame = frame.astype(float)\n",
        "    features_to_scale = [\"SMA_10\", \"SMA_50\", \"RSI_14\", \"Middle_Band\", \"Upper_Band\", \"Lower_Band\", \"TOD\"]\n",
        "    scaler = StandardScaler()\n",
        "    frame[features_to_scale] = scaler.fit_transform(frame[features_to_scale])\n",
        "    target = frame.pop('Return_Signal')\n",
        "    xtr, xte, ytr, yte = train_test_split(frame, target, test_size=0.2, shuffle=False)\n",
        "    train_shape = xtr.shape\n",
        "    x_train, y_train = sequence_maker(xtr.to_numpy(), ytr.to_numpy(), timesteps)\n",
        "    x_test, y_test = sequence_maker(xte.to_numpy(), yte.to_numpy(), timesteps)\n",
        "    w = compute_class_weight('balanced', classes=np.unique([0.0, 1.0, 2.0]), y=y_train)\n",
        "    weights = {0: w[0], 1: w[1], 2: w[2]}\n",
        "    test_shape = xte.shape\n",
        "    return  x_train, x_test, y_train, y_test, weights, train_shape\n",
        "\n",
        "\n",
        "x_train, x_test, y_train, y_test, weights, shape = build_generators(\"drive/MyDrive/KC/XDGUSD_15_with_features.csv\", timesteps)\n",
        "print(weights)\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(batch_size).shuffle(1000).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size).prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "URt_KkFTI3Aj"
      },
      "outputs": [],
      "source": [
        "class ClassSpecificAccuracy(tf.keras.metrics.Metric):\n",
        "    def __init__(self, target_class=2, name=\"class_accuracy\", **kwargs):\n",
        "        name = f\"{name}_{target_class}\"\n",
        "        super().__init__(name=name, **kwargs)\n",
        "        self.target_class = target_class\n",
        "        self.correct = self.add_weight(name=\"correct\", initializer=\"zeros\")\n",
        "        self.total = self.add_weight(name=\"total\", initializer=\"zeros\")\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        y_true = tf.cast(y_true, tf.int64)\n",
        "        y_pred_labels = tf.argmax(y_pred, axis=1, output_type=tf.int64)\n",
        "\n",
        "        mask = tf.equal(y_true, self.target_class)\n",
        "        correct_preds = tf.reduce_sum(tf.cast(tf.logical_and(mask, tf.equal(y_pred_labels, y_true)), tf.float32))\n",
        "        total_preds = tf.reduce_sum(tf.cast(mask, tf.float32))\n",
        "\n",
        "        self.correct.assign_add(correct_preds)\n",
        "        self.total.assign_add(total_preds)\n",
        "\n",
        "    def result(self):\n",
        "        return self.correct / (self.total + tf.keras.backend.epsilon())\n",
        "\n",
        "    def reset_states(self):\n",
        "        self.correct.assign(0)\n",
        "        self.total.assign(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cGrp1qsuFamR"
      },
      "outputs": [],
      "source": [
        "class ClassSpecificPrecision(tf.keras.metrics.Metric):\n",
        "    def __init__(self, target_class=2, name=\"class_precision\", **kwargs):\n",
        "        name = f\"{name}_{target_class}\"\n",
        "        super().__init__(name=name, **kwargs)\n",
        "        self.target_class = target_class\n",
        "        self.correct = self.add_weight(name=\"correct\", initializer=\"zeros\")\n",
        "        self.total_predicted = self.add_weight(name=\"total_predicted\", initializer=\"zeros\")\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        y_true = tf.cast(y_true, tf.int64)\n",
        "        y_pred_labels = tf.argmax(y_pred, axis=1, output_type=tf.int64)\n",
        "\n",
        "        # Mask: Find where predictions are the target class\n",
        "        mask = tf.equal(y_pred_labels, self.target_class)\n",
        "\n",
        "        # Correct predictions: Where the true label is also the target class\n",
        "        correct_preds = tf.reduce_sum(tf.cast(tf.logical_and(mask, tf.equal(y_pred_labels, y_true)), tf.float32))\n",
        "\n",
        "        # Total predictions of the target class\n",
        "        total_predicted = tf.reduce_sum(tf.cast(mask, tf.float32))\n",
        "\n",
        "        # Update metric\n",
        "        self.correct.assign_add(correct_preds)\n",
        "        self.total_predicted.assign_add(total_predicted)\n",
        "\n",
        "    def result(self):\n",
        "        return self.correct / (self.total_predicted + tf.keras.backend.epsilon())\n",
        "\n",
        "    def reset_states(self):\n",
        "        self.correct.assign(0)\n",
        "        self.total_predicted.assign(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dLetwDDNniP",
        "outputId": "fd42ce7d-22d1-4dff-d674-5b2ca973eabb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on CPU/GPU\n",
            "Running on <tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7800d2b8b790>\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # Detect TPU\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.TPUStrategy(tpu)  # Use TPU Strategy\n",
        "    print(\"Running on TPU\")\n",
        "except ValueError:\n",
        "    strategy = tf.distribute.get_strategy()  # Fallback to CPU/GPU\n",
        "    print(\"Running on CPU/GPU\")\n",
        "    print(\"Running on\", strategy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZQ_XNXuJabi",
        "outputId": "c4f8eb34-94f8-454a-aa58-67b6180f6fee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 16ms/step - accuracy: 0.4028 - class_accuracy_2: 0.3541 - class_precision_2: 0.1392 - loss: 0.9832 - val_accuracy: 0.1742 - val_class_accuracy_2: 0.9306 - val_class_precision_2: 0.1305 - val_loss: 1.2465\n",
            "Epoch 2/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 15ms/step - accuracy: 0.3870 - class_accuracy_2: 0.4461 - class_precision_2: 0.1416 - loss: 0.9639 - val_accuracy: 0.2341 - val_class_accuracy_2: 0.8000 - val_class_precision_2: 0.1452 - val_loss: 1.2233\n",
            "Epoch 3/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 15ms/step - accuracy: 0.3788 - class_accuracy_2: 0.4803 - class_precision_2: 0.1467 - loss: 0.9634 - val_accuracy: 0.3162 - val_class_accuracy_2: 0.5017 - val_class_precision_2: 0.1637 - val_loss: 1.0445\n",
            "Epoch 4/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 16ms/step - accuracy: 0.3929 - class_accuracy_2: 0.4812 - class_precision_2: 0.1589 - loss: 0.9609 - val_accuracy: 0.3760 - val_class_accuracy_2: 0.0000e+00 - val_class_precision_2: 0.0000e+00 - val_loss: 0.9950\n",
            "Epoch 5/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 15ms/step - accuracy: 0.3819 - class_accuracy_2: 0.3170 - class_precision_2: 0.1075 - loss: 0.9850 - val_accuracy: 0.2180 - val_class_accuracy_2: 0.8430 - val_class_precision_2: 0.1355 - val_loss: 1.1250\n",
            "Epoch 6/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.3862 - class_accuracy_2: 0.4167 - class_precision_2: 0.1366 - loss: 0.9742 - val_accuracy: 0.1270 - val_class_accuracy_2: 0.9917 - val_class_precision_2: 0.1221 - val_loss: 1.2012\n",
            "Epoch 7/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 15ms/step - accuracy: 0.3701 - class_accuracy_2: 0.3020 - class_precision_2: 0.0940 - loss: 1.0097 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1299\n",
            "Epoch 8/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.3621 - class_accuracy_2: 0.3010 - class_precision_2: 0.0846 - loss: 1.0037 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1120\n",
            "Epoch 9/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 15ms/step - accuracy: 0.3721 - class_accuracy_2: 0.2622 - class_precision_2: 0.0735 - loss: 1.0120 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1096\n",
            "Epoch 10/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 15ms/step - accuracy: 0.3777 - class_accuracy_2: 0.2319 - class_precision_2: 0.0829 - loss: 1.0189 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1195\n",
            "Epoch 11/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.3660 - class_accuracy_2: 0.2728 - class_precision_2: 0.0880 - loss: 1.0131 - val_accuracy: 0.5027 - val_class_accuracy_2: 0.0000e+00 - val_class_precision_2: 0.0000e+00 - val_loss: 1.0971\n",
            "Epoch 12/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.3809 - class_accuracy_2: 0.2296 - class_precision_2: 0.0741 - loss: 1.0118 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1475\n",
            "Epoch 13/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 16ms/step - accuracy: 0.3450 - class_accuracy_2: 0.3180 - class_precision_2: 0.0886 - loss: 1.0213 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1807\n",
            "Epoch 14/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 15ms/step - accuracy: 0.3537 - class_accuracy_2: 0.3285 - class_precision_2: 0.0929 - loss: 1.0082 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1356\n",
            "Epoch 15/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.3578 - class_accuracy_2: 0.3023 - class_precision_2: 0.1005 - loss: 1.0238 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1821\n",
            "Epoch 16/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.3450 - class_accuracy_2: 0.3361 - class_precision_2: 0.0859 - loss: 1.0065 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1602\n",
            "Epoch 17/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.3492 - class_accuracy_2: 0.2996 - class_precision_2: 0.0821 - loss: 1.0206 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1391\n",
            "Epoch 18/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.3596 - class_accuracy_2: 0.2974 - class_precision_2: 0.0903 - loss: 1.0156 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1479\n",
            "Epoch 19/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 16ms/step - accuracy: 0.3561 - class_accuracy_2: 0.3113 - class_precision_2: 0.0845 - loss: 1.0034 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1545\n",
            "Epoch 20/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.3584 - class_accuracy_2: 0.2483 - class_precision_2: 0.0733 - loss: 1.0124 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1607\n",
            "Epoch 21/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.3436 - class_accuracy_2: 0.3089 - class_precision_2: 0.0921 - loss: 1.0216 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1369\n",
            "Epoch 22/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.3472 - class_accuracy_2: 0.3116 - class_precision_2: 0.0875 - loss: 1.0125 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1564\n",
            "Epoch 23/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.3451 - class_accuracy_2: 0.2729 - class_precision_2: 0.0810 - loss: 1.0200 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1556\n",
            "Epoch 24/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 15ms/step - accuracy: 0.3428 - class_accuracy_2: 0.3336 - class_precision_2: 0.0926 - loss: 1.0117 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1501\n",
            "Epoch 25/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.3616 - class_accuracy_2: 0.2834 - class_precision_2: 0.0784 - loss: 1.0063 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1601\n",
            "Epoch 26/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.3553 - class_accuracy_2: 0.2649 - class_precision_2: 0.0788 - loss: 1.0080 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1049\n",
            "Epoch 27/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.3571 - class_accuracy_2: 0.2865 - class_precision_2: 0.0719 - loss: 1.0108 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1039\n",
            "Epoch 28/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 15ms/step - accuracy: 0.3818 - class_accuracy_2: 0.2331 - class_precision_2: 0.0730 - loss: 1.0063 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1963\n",
            "Epoch 29/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 15ms/step - accuracy: 0.3352 - class_accuracy_2: 0.3784 - class_precision_2: 0.0977 - loss: 1.0233 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1360\n",
            "Epoch 30/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 16ms/step - accuracy: 0.3399 - class_accuracy_2: 0.3162 - class_precision_2: 0.0909 - loss: 1.0184 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1316\n",
            "Epoch 31/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.3416 - class_accuracy_2: 0.3055 - class_precision_2: 0.0887 - loss: 1.0109 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1368\n",
            "Epoch 32/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 16ms/step - accuracy: 0.3620 - class_accuracy_2: 0.2788 - class_precision_2: 0.0818 - loss: 1.0059 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1480\n",
            "Epoch 33/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 15ms/step - accuracy: 0.3372 - class_accuracy_2: 0.3614 - class_precision_2: 0.0914 - loss: 1.0056 - val_accuracy: 0.3760 - val_class_accuracy_2: 0.0000e+00 - val_class_precision_2: 0.0000e+00 - val_loss: 1.1064\n",
            "Epoch 34/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 15ms/step - accuracy: 0.3513 - class_accuracy_2: 0.2898 - class_precision_2: 0.0948 - loss: 1.0214 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1332\n",
            "Epoch 35/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.3660 - class_accuracy_2: 0.2331 - class_precision_2: 0.0719 - loss: 1.0099 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1192\n",
            "Epoch 36/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.3559 - class_accuracy_2: 0.2913 - class_precision_2: 0.0821 - loss: 1.0116 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1238\n",
            "Epoch 37/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 15ms/step - accuracy: 0.3648 - class_accuracy_2: 0.2711 - class_precision_2: 0.0900 - loss: 1.0074 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1431\n",
            "Epoch 38/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 15ms/step - accuracy: 0.3599 - class_accuracy_2: 0.2419 - class_precision_2: 0.0706 - loss: 1.0190 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1535\n",
            "Epoch 39/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.3436 - class_accuracy_2: 0.3263 - class_precision_2: 0.0898 - loss: 1.0158 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1734\n",
            "Epoch 40/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 16ms/step - accuracy: 0.3465 - class_accuracy_2: 0.2756 - class_precision_2: 0.0784 - loss: 1.0118 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1537\n",
            "Epoch 41/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 15ms/step - accuracy: 0.3501 - class_accuracy_2: 0.2862 - class_precision_2: 0.0774 - loss: 1.0120 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1297\n",
            "Epoch 42/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.3641 - class_accuracy_2: 0.2795 - class_precision_2: 0.0901 - loss: 1.0107 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1229\n",
            "Epoch 43/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 16ms/step - accuracy: 0.3677 - class_accuracy_2: 0.2710 - class_precision_2: 0.0738 - loss: 1.0116 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1431\n",
            "Epoch 44/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.3580 - class_accuracy_2: 0.2512 - class_precision_2: 0.0793 - loss: 1.0137 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1039\n",
            "Epoch 45/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 16ms/step - accuracy: 0.3736 - class_accuracy_2: 0.2428 - class_precision_2: 0.0885 - loss: 1.0155 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1311\n",
            "Epoch 46/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 15ms/step - accuracy: 0.3596 - class_accuracy_2: 0.2694 - class_precision_2: 0.0821 - loss: 1.0111 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1327\n",
            "Epoch 47/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 16ms/step - accuracy: 0.3512 - class_accuracy_2: 0.2889 - class_precision_2: 0.0918 - loss: 1.0243 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1441\n",
            "Epoch 48/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 15ms/step - accuracy: 0.3710 - class_accuracy_2: 0.2253 - class_precision_2: 0.0725 - loss: 1.0080 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1597\n",
            "Epoch 49/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 15ms/step - accuracy: 0.3604 - class_accuracy_2: 0.2689 - class_precision_2: 0.0793 - loss: 1.0170 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1136\n",
            "Epoch 50/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 15ms/step - accuracy: 0.3616 - class_accuracy_2: 0.3039 - class_precision_2: 0.0985 - loss: 1.0048 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1571\n",
            "Epoch 51/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 15ms/step - accuracy: 0.3438 - class_accuracy_2: 0.3188 - class_precision_2: 0.0902 - loss: 1.0200 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1854\n",
            "Epoch 52/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.3499 - class_accuracy_2: 0.2780 - class_precision_2: 0.0848 - loss: 1.0290 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1442\n",
            "Epoch 53/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.3555 - class_accuracy_2: 0.2743 - class_precision_2: 0.0735 - loss: 1.0082 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1267\n",
            "Epoch 54/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.3642 - class_accuracy_2: 0.2716 - class_precision_2: 0.0748 - loss: 1.0074 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1122\n",
            "Epoch 55/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 15ms/step - accuracy: 0.3735 - class_accuracy_2: 0.2354 - class_precision_2: 0.0751 - loss: 1.0124 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1216\n",
            "Epoch 56/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 15ms/step - accuracy: 0.3584 - class_accuracy_2: 0.2717 - class_precision_2: 0.0731 - loss: 1.0023 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1549\n",
            "Epoch 57/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 15ms/step - accuracy: 0.3436 - class_accuracy_2: 0.2988 - class_precision_2: 0.0812 - loss: 1.0173 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1299\n",
            "Epoch 58/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.3574 - class_accuracy_2: 0.2870 - class_precision_2: 0.0865 - loss: 1.0071 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1305\n",
            "Epoch 59/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 16ms/step - accuracy: 0.3550 - class_accuracy_2: 0.2967 - class_precision_2: 0.0920 - loss: 1.0142 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1828\n",
            "Epoch 60/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.3428 - class_accuracy_2: 0.3239 - class_precision_2: 0.0834 - loss: 1.0067 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1302\n",
            "Epoch 61/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.3739 - class_accuracy_2: 0.2396 - class_precision_2: 0.0838 - loss: 1.0090 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1734\n",
            "Epoch 62/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.3440 - class_accuracy_2: 0.3134 - class_precision_2: 0.0873 - loss: 1.0142 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1106\n",
            "Epoch 63/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 15ms/step - accuracy: 0.3647 - class_accuracy_2: 0.2877 - class_precision_2: 0.1042 - loss: 1.0086 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1948\n",
            "Epoch 64/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 15ms/step - accuracy: 0.3572 - class_accuracy_2: 0.2165 - class_precision_2: 0.0687 - loss: 1.0162 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1715\n",
            "Epoch 65/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.3412 - class_accuracy_2: 0.3256 - class_precision_2: 0.0843 - loss: 1.0167 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1314\n",
            "Epoch 66/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.3689 - class_accuracy_2: 0.2675 - class_precision_2: 0.0864 - loss: 1.0151 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1469\n",
            "Epoch 67/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 16ms/step - accuracy: 0.3632 - class_accuracy_2: 0.2822 - class_precision_2: 0.0907 - loss: 1.0103 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1255\n",
            "Epoch 68/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 15ms/step - accuracy: 0.3639 - class_accuracy_2: 0.2567 - class_precision_2: 0.0805 - loss: 1.0122 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1174\n",
            "Epoch 69/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 16ms/step - accuracy: 0.3572 - class_accuracy_2: 0.3132 - class_precision_2: 0.0942 - loss: 1.0063 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1672\n",
            "Epoch 70/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 15ms/step - accuracy: 0.3463 - class_accuracy_2: 0.3132 - class_precision_2: 0.0993 - loss: 1.0226 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1618\n",
            "Epoch 71/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.3595 - class_accuracy_2: 0.2740 - class_precision_2: 0.0785 - loss: 1.0179 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1441\n",
            "Epoch 72/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 15ms/step - accuracy: 0.3627 - class_accuracy_2: 0.2508 - class_precision_2: 0.0753 - loss: 1.0174 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1336\n",
            "Epoch 73/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.3711 - class_accuracy_2: 0.2344 - class_precision_2: 0.0842 - loss: 1.0174 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1553\n",
            "Epoch 74/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 16ms/step - accuracy: 0.3563 - class_accuracy_2: 0.2964 - class_precision_2: 0.0940 - loss: 1.0113 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1374\n",
            "Epoch 75/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.3727 - class_accuracy_2: 0.2673 - class_precision_2: 0.0988 - loss: 1.0139 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1729\n",
            "Epoch 76/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.3646 - class_accuracy_2: 0.2415 - class_precision_2: 0.0719 - loss: 1.0075 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1346\n",
            "Epoch 77/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.3655 - class_accuracy_2: 0.2547 - class_precision_2: 0.0881 - loss: 1.0079 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1687\n",
            "Epoch 78/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 15ms/step - accuracy: 0.3574 - class_accuracy_2: 0.3010 - class_precision_2: 0.0921 - loss: 1.0024 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1833\n",
            "Epoch 79/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.3546 - class_accuracy_2: 0.2911 - class_precision_2: 0.0876 - loss: 1.0086 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1309\n",
            "Epoch 80/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 15ms/step - accuracy: 0.3715 - class_accuracy_2: 0.2539 - class_precision_2: 0.0750 - loss: 1.0116 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1511\n",
            "Epoch 81/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 16ms/step - accuracy: 0.3576 - class_accuracy_2: 0.2665 - class_precision_2: 0.0768 - loss: 1.0014 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.0994\n",
            "Epoch 82/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 15ms/step - accuracy: 0.3748 - class_accuracy_2: 0.2270 - class_precision_2: 0.0697 - loss: 1.0105 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1741\n",
            "Epoch 83/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.3510 - class_accuracy_2: 0.2789 - class_precision_2: 0.0775 - loss: 1.0165 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1664\n",
            "Epoch 84/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 15ms/step - accuracy: 0.3605 - class_accuracy_2: 0.2656 - class_precision_2: 0.0902 - loss: 1.0210 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1563\n",
            "Epoch 85/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 15ms/step - accuracy: 0.3742 - class_accuracy_2: 0.2275 - class_precision_2: 0.0756 - loss: 1.0104 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1117\n",
            "Epoch 86/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 15ms/step - accuracy: 0.3774 - class_accuracy_2: 0.2471 - class_precision_2: 0.0777 - loss: 1.0105 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1194\n",
            "Epoch 87/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.3674 - class_accuracy_2: 0.2655 - class_precision_2: 0.0806 - loss: 1.0080 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1284\n",
            "Epoch 88/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 16ms/step - accuracy: 0.3753 - class_accuracy_2: 0.2625 - class_precision_2: 0.0727 - loss: 1.0038 - val_accuracy: 0.3760 - val_class_accuracy_2: 0.0000e+00 - val_class_precision_2: 0.0000e+00 - val_loss: 1.0891\n",
            "Epoch 89/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 15ms/step - accuracy: 0.3614 - class_accuracy_2: 0.2675 - class_precision_2: 0.0724 - loss: 1.0153 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1170\n",
            "Epoch 90/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.3653 - class_accuracy_2: 0.2471 - class_precision_2: 0.0876 - loss: 1.0156 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1648\n",
            "Epoch 91/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.3802 - class_accuracy_2: 0.2153 - class_precision_2: 0.0800 - loss: 1.0197 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1472\n",
            "Epoch 92/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 16ms/step - accuracy: 0.3669 - class_accuracy_2: 0.2601 - class_precision_2: 0.0851 - loss: 1.0103 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1551\n",
            "Epoch 93/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 15ms/step - accuracy: 0.3723 - class_accuracy_2: 0.2494 - class_precision_2: 0.0795 - loss: 1.0064 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1850\n",
            "Epoch 94/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 16ms/step - accuracy: 0.3628 - class_accuracy_2: 0.2296 - class_precision_2: 0.0729 - loss: 1.0222 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1098\n",
            "Epoch 95/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.3788 - class_accuracy_2: 0.2361 - class_precision_2: 0.0855 - loss: 1.0156 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1378\n",
            "Epoch 96/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 16ms/step - accuracy: 0.3792 - class_accuracy_2: 0.2301 - class_precision_2: 0.0743 - loss: 0.9971 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1524\n",
            "Epoch 97/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 16ms/step - accuracy: 0.3574 - class_accuracy_2: 0.2606 - class_precision_2: 0.0768 - loss: 1.0262 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1385\n",
            "Epoch 98/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.3688 - class_accuracy_2: 0.2792 - class_precision_2: 0.0956 - loss: 1.0221 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1577\n",
            "Epoch 99/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 16ms/step - accuracy: 0.3561 - class_accuracy_2: 0.3005 - class_precision_2: 0.1000 - loss: 1.0207 - val_accuracy: 0.1213 - val_class_accuracy_2: 1.0000 - val_class_precision_2: 0.1213 - val_loss: 1.1043\n",
            "Epoch 100/100\n",
            "\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.3861 - class_accuracy_2: 0.2180 - class_precision_2: 0.0777 - loss: 1.0034 - val_accuracy: 0.5027 - val_class_accuracy_2: 0.0000e+00 - val_class_precision_2: 0.0000e+00 - val_loss: 1.0624\n",
            "\u001b[1m624/624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.5017 - class_accuracy_2: 0.0000e+00 - class_precision_2: 0.0000e+00 - loss: 1.0629\n",
            "Test accuracy: 0.5027064681053162\n",
            "Class 2 accuracy: 0.0\n",
            "Class 2 precision: 0.0\n"
          ]
        }
      ],
      "source": [
        "#Specify list of layers\n",
        "layer_list = [\n",
        "    Input(shape=(timesteps, shape[1])),\n",
        "    Bidirectional(layers.LSTM(128, return_sequences=True)),\n",
        "    Bidirectional(layers.LSTM(128, return_sequences=True)),\n",
        "    Bidirectional(layers.LSTM(128, return_sequences=False)),\n",
        "    layers.Dense(100, activation='relu'),\n",
        "    layers.Dense(3, activation='softmax')\n",
        "\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "with strategy.scope():\n",
        "    model = models.Sequential(layer_list)\n",
        "    optim = tf.keras.optimizers.RMSprop(learning_rate=0.0005)\n",
        "    model.compile(optimizer=optim, loss='sparse_categorical_crossentropy', metrics=['accuracy', ClassSpecificAccuracy(target_class=2), ClassSpecificPrecision(target_class=2)])\n",
        "    model.fit(train_dataset, class_weight=weights, epochs=epochs, validation_data=test_dataset)\n",
        "\n",
        "test_loss, test_acc, class_2_acc, class_2_prec = model.evaluate(test_dataset)\n",
        "print('Test accuracy:', test_acc)\n",
        "print('Class 2 accuracy:', class_2_acc)\n",
        "print('Class 2 precision:', class_2_prec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qbQ0n-r6xO7N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c47b6f29-e933-4e22-dc9c-6b8bfaa2beb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step\n",
            "Predicted Class Distribution: {1: 9993}\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(test_dataset)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)  # Convert softmax output to class predictions\n",
        "\n",
        "# Count occurrences of each predicted class\n",
        "unique, counts = np.unique(y_pred_classes, return_counts=True)\n",
        "print(\"Predicted Class Distribution:\", dict(zip(unique, counts)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "AKVlClf52Lcz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f0aed78-8643-47ff-c4da-b570bc092bc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.35450786 0.35747004 0.28802204]\n",
            " [0.35450786 0.35747004 0.28802204]\n",
            " [0.35450786 0.35747004 0.28802204]\n",
            " [0.35450786 0.35747004 0.28802204]\n",
            " [0.35450786 0.35747004 0.28802204]\n",
            " [0.35450786 0.35747004 0.28802204]\n",
            " [0.35450786 0.35747004 0.28802204]\n",
            " [0.35450786 0.35747004 0.28802204]\n",
            " [0.35450786 0.35747004 0.28802204]\n",
            " [0.35450786 0.35747004 0.28802204]\n",
            " [0.35450786 0.35747004 0.28802204]\n",
            " [0.35450786 0.35747004 0.28802204]\n",
            " [0.35450786 0.35747004 0.28802204]\n",
            " [0.35450786 0.35747004 0.28802204]\n",
            " [0.35450786 0.35747004 0.28802204]\n",
            " [0.35450786 0.35747004 0.28802204]\n",
            " [0.35450786 0.35747004 0.28802204]\n",
            " [0.35450786 0.35747004 0.28802204]\n",
            " [0.35450786 0.35747004 0.28802204]\n",
            " [0.35450786 0.35747004 0.28802204]]\n",
            "[]\n"
          ]
        }
      ],
      "source": [
        "print(y_pred[:20])\n",
        "print([i for i in y_pred if max(i)==i[2]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "mjFkt6gdbowp"
      },
      "outputs": [],
      "source": [
        "from google.colab import runtime\n",
        "\n",
        "runtime.unassign()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}